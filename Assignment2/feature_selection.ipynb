{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\franc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from IPython.display import display\n",
    "from sklearn import naive_bayes, linear_model, tree, ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(path, fold_nrs, label):\n",
    "    columns = ['Raw', 'Processed', 'Label']\n",
    "    df = pd.DataFrame()\n",
    "    for i in fold_nrs:\n",
    "        fold = \"fold\"+str(i)\n",
    "        p = path + fold\n",
    "        for file in os.listdir(p): # for each .txt file in this fold's folder\n",
    "            if file.endswith(\".txt\"):\n",
    "                f = open(os.path.join(p, file), \"r\")\n",
    "                review = f.read()\n",
    "                # remove whitespaces, numbers, punctuation, & make lowercase\n",
    "                processed = process_string(review)\n",
    "                new_row = pd.DataFrame([[review, processed, label]])\n",
    "                df = df.append(new_row)\n",
    "    df.columns = columns\n",
    "    return df\n",
    "\n",
    "def make_train_test_set():\n",
    "    # Focusing only on the negative reviews\n",
    "    path_dec = \"./op_spam_v1.4/negative_polarity/deceptive_from_MTurk/\"\n",
    "    path_true = \"./op_spam_v1.4/negative_polarity/truthful_from_Web/\"\n",
    "\n",
    "    # Label = 1 if it is a truthful (negative) review, =0 if it is a deceptive (negative) review\n",
    "\n",
    "    #loading training set:\n",
    "    train_dec = load_reviews(path_dec, np.arange(4)+1, 0) # folds 1-4 form the training set\n",
    "    train_true = load_reviews(path_true, np.arange(4)+1, 1)\n",
    "    train = pd.concat([train_dec, train_true])\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    #loading the test set:\n",
    "    test_dec = load_reviews(path_dec, [5], 0)  # test set for deceptive reviews\n",
    "    test_true = load_reviews(path_true, [5], 1)\n",
    "    test = pd.concat([test_dec, test_true])\n",
    "    test = test.reset_index(drop=True)\n",
    "\n",
    "    return [train,test]\n",
    "\n",
    "def process_string(s):\n",
    "    s = s.strip()    # remove whitespaces\n",
    "    s = s.lower() # to lowercase\n",
    "    s = re.sub(r'\\d+', '', s) # remove numbers\n",
    "    s = s.translate(str.maketrans(\"\",\"\", string.punctuation)) # remove punctuation\n",
    "    return s\n",
    "\n",
    "\n",
    "##########################\n",
    "###Process files to CSV###\n",
    "##########################\n",
    "\n",
    "train, test = make_train_test_set()\n",
    "train.to_csv(\"./train.csv\", header = ['Raw', 'Processed', 'Label'], index=False)\n",
    "test.to_csv(\"./test.csv\", header = ['Raw', 'Processed', 'Label'], index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape of training set: (640, 3)\n",
      "                                                 Raw  \\\n",
      "0  We stayed at the Schicago Hilton for 4 days an...   \n",
      "1  Hotel is located 1/2 mile from the train stati...   \n",
      "2  I made my reservation at the Hilton Chicago be...   \n",
      "3  When most people think Hilton, they think luxu...   \n",
      "4  My husband and I recently stayed stayed at the...   \n",
      "\n",
      "                                           Processed  Label  \n",
      "0  we stayed at the schicago hilton for  days and...      0  \n",
      "1  hotel is located  mile from the train station ...      0  \n",
      "2  i made my reservation at the hilton chicago be...      0  \n",
      "3  when most people think hilton they think luxur...      0  \n",
      "4  my husband and i recently stayed stayed at the...      0  \n",
      "\n",
      " Shape of test set: (160, 3)\n",
      "                                                 Raw  \\\n",
      "0  I recently stayed at the Hotel Allegro Chicago...   \n",
      "1  I recently stayed at the Hotel Allegro in Chic...   \n",
      "2  I recently visited Chicago. I stayed at the Ho...   \n",
      "3  I visited the Hotel Allegro Chicago while I wa...   \n",
      "4  I was unimpressed by the quality of this hotel...   \n",
      "\n",
      "                                           Processed  Label  \n",
      "0  i recently stayed at the hotel allegro chicago...      0  \n",
      "1  i recently stayed at the hotel allegro in chic...      0  \n",
      "2  i recently visited chicago i stayed at the hot...      0  \n",
      "3  i visited the hotel allegro chicago while i wa...      0  \n",
      "4  i was unimpressed by the quality of this hotel...      0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>Processed</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We stayed at the Schicago Hilton for 4 days an...</td>\n",
       "      <td>we stayed at the schicago hilton for  days and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel is located 1/2 mile from the train stati...</td>\n",
       "      <td>hotel is located  mile from the train station ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I made my reservation at the Hilton Chicago be...</td>\n",
       "      <td>i made my reservation at the hilton chicago be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When most people think Hilton, they think luxu...</td>\n",
       "      <td>when most people think hilton they think luxur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My husband and I recently stayed stayed at the...</td>\n",
       "      <td>my husband and i recently stayed stayed at the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Raw  \\\n",
       "0  We stayed at the Schicago Hilton for 4 days an...   \n",
       "1  Hotel is located 1/2 mile from the train stati...   \n",
       "2  I made my reservation at the Hilton Chicago be...   \n",
       "3  When most people think Hilton, they think luxu...   \n",
       "4  My husband and I recently stayed stayed at the...   \n",
       "\n",
       "                                           Processed  Label  \n",
       "0  we stayed at the schicago hilton for  days and...      0  \n",
       "1  hotel is located  mile from the train station ...      0  \n",
       "2  i made my reservation at the hilton chicago be...      0  \n",
       "3  when most people think hilton they think luxur...      0  \n",
       "4  my husband and i recently stayed stayed at the...      0  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"\\n Shape of training set: {train.shape}\")\n",
    "print(train.head())\n",
    "print(f\"\\n Shape of test set: {test.shape}\")\n",
    "print(test.head())\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words must appear at least in 1.0% of the reviews to become feature\n",
      "The model contains 1255 features\n",
      "Words must appear at least in 5.0% of the reviews to become feature\n",
      "The model contains 337 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>ac</th>\n",
       "      <th>access</th>\n",
       "      <th>accommodate</th>\n",
       "      <th>accommodations</th>\n",
       "      <th>account</th>\n",
       "      <th>across</th>\n",
       "      <th>acted</th>\n",
       "      <th>actual</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yelling</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>youd</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  absolutely   ac    access  accommodate  accommodations  account  \\\n",
       "99    0.0         0.0  0.0  0.000000          0.0             0.0      0.0   \n",
       "375   0.0         0.0  0.0  0.000000          0.0             0.0      0.0   \n",
       "330   0.0         0.0  0.0  0.256244          0.0             0.0      0.0   \n",
       "526   0.0         0.0  0.0  0.000000          0.0             0.0      0.0   \n",
       "404   0.0         0.0  0.0  0.000000          0.0             0.0      0.0   \n",
       "\n",
       "     across  acted  actual  ...     write  wrong  year  years  yelling  yes  \\\n",
       "99      0.0    0.0     0.0  ...  0.000000    0.0   0.0    0.0      0.0  0.0   \n",
       "375     0.0    0.0     0.0  ...  0.000000    0.0   0.0    0.0      0.0  0.0   \n",
       "330     0.0    0.0     0.0  ...  0.000000    0.0   0.0    0.0      0.0  0.0   \n",
       "526     0.0    0.0     0.0  ...  0.000000    0.0   0.0    0.0      0.0  0.0   \n",
       "404     0.0    0.0     0.0  ...  0.159819    0.0   0.0    0.0      0.0  0.0   \n",
       "\n",
       "     yet  youd  young  youre  \n",
       "99   0.0   0.0    0.0    0.0  \n",
       "375  0.0   0.0    0.0    0.0  \n",
       "330  0.0   0.0    0.0    0.0  \n",
       "526  0.0   0.0    0.0    0.0  \n",
       "404  0.0   0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 1255 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "99     0\n",
       "375    1\n",
       "330    1\n",
       "526    1\n",
       "404    1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>ac</th>\n",
       "      <th>access</th>\n",
       "      <th>accommodate</th>\n",
       "      <th>accommodations</th>\n",
       "      <th>account</th>\n",
       "      <th>across</th>\n",
       "      <th>acted</th>\n",
       "      <th>actual</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yelling</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>youd</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  absolutely   ac  access  accommodate  accommodations  account  \\\n",
       "141   0.0         0.0  0.0     0.0          0.0             0.0      0.0   \n",
       "39    0.0         0.0  0.0     0.0          0.0             0.0      0.0   \n",
       "121   0.0         0.0  0.0     0.0          0.0             0.0      0.0   \n",
       "28    0.0         0.0  0.0     0.0          0.0             0.0      0.0   \n",
       "129   0.0         0.0  0.0     0.0          0.0             0.0      0.0   \n",
       "\n",
       "     across  acted  actual  ...  write  wrong      year  years  yelling  yes  \\\n",
       "141     0.0    0.0     0.0  ...    0.0    0.0  0.000000    0.0      0.0  0.0   \n",
       "39      0.0    0.0     0.0  ...    0.0    0.0  0.000000    0.0      0.0  0.0   \n",
       "121     0.0    0.0     0.0  ...    0.0    0.0  0.000000    0.0      0.0  0.0   \n",
       "28      0.0    0.0     0.0  ...    0.0    0.0  0.000000    0.0      0.0  0.0   \n",
       "129     0.0    0.0     0.0  ...    0.0    0.0  0.145127    0.0      0.0  0.0   \n",
       "\n",
       "     yet  youd  young  youre  \n",
       "141  0.0   0.0    0.0    0.0  \n",
       "39   0.0   0.0    0.0    0.0  \n",
       "121  0.0   0.0    0.0    0.0  \n",
       "28   0.0   0.0    0.0    0.0  \n",
       "129  0.0   0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 1255 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "141    1\n",
       "39     0\n",
       "121    1\n",
       "28     0\n",
       "129    1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>actually</th>\n",
       "      <th>air</th>\n",
       "      <th>almost</th>\n",
       "      <th>already</th>\n",
       "      <th>also</th>\n",
       "      <th>although</th>\n",
       "      <th>amenities</th>\n",
       "      <th>another</th>\n",
       "      <th>anyone</th>\n",
       "      <th>...</th>\n",
       "      <th>without</th>\n",
       "      <th>wont</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150668</td>\n",
       "      <td>0.055138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071217</td>\n",
       "      <td>0.174739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075849</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  actually  air  almost  already      also  although  amenities  \\\n",
       "51    0.0       0.0  0.0     0.0      0.0  0.161768       0.0   0.000000   \n",
       "564   0.0       0.0  0.0     0.0      0.0  0.000000       0.0   0.000000   \n",
       "573   0.0       0.0  0.0     0.0      0.0  0.000000       0.0   0.000000   \n",
       "529   0.0       0.0  0.0     0.0      0.0  0.152142       0.0   0.150668   \n",
       "141   0.0       0.0  0.0     0.0      0.0  0.143070       0.0   0.000000   \n",
       "\n",
       "      another  anyone  ...  without  wont      work  working  worst     worth  \\\n",
       "51   0.000000     0.0  ...      0.0   0.0  0.000000      0.0    0.0  0.000000   \n",
       "564  0.000000     0.0  ...      0.0   0.0  0.000000      0.0    0.0  0.000000   \n",
       "573  0.000000     0.0  ...      0.0   0.0  0.000000      0.0    0.0  0.000000   \n",
       "529  0.055138     0.0  ...      0.0   0.0  0.059199      0.0    0.0  0.071217   \n",
       "141  0.000000     0.0  ...      0.0   0.0  0.000000      0.0    0.0  0.200912   \n",
       "\n",
       "        would  would recommend   wouldnt  wrong  \n",
       "51   0.000000              0.0  0.000000    0.0  \n",
       "564  0.101549              0.0  0.000000    0.0  \n",
       "573  0.160973              0.0  0.000000    0.0  \n",
       "529  0.174739              0.0  0.075849    0.0  \n",
       "141  0.000000              0.0  0.000000    0.0  \n",
       "\n",
       "[5 rows x 337 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "51     0\n",
       "564    1\n",
       "573    1\n",
       "529    1\n",
       "141    0\n",
       "Name: Label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>actually</th>\n",
       "      <th>air</th>\n",
       "      <th>almost</th>\n",
       "      <th>already</th>\n",
       "      <th>also</th>\n",
       "      <th>although</th>\n",
       "      <th>amenities</th>\n",
       "      <th>another</th>\n",
       "      <th>anyone</th>\n",
       "      <th>...</th>\n",
       "      <th>without</th>\n",
       "      <th>wont</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  actually  air  almost  already  also  although  amenities  another  \\\n",
       "156   0.0       0.0  0.0     0.0      0.0   0.0  0.000000   0.000000      0.0   \n",
       "67    0.0       0.0  0.0     0.0      0.0   0.0  0.000000   0.000000      0.0   \n",
       "118   0.0       0.0  0.0     0.0      0.0   0.0  0.208943   0.000000      0.0   \n",
       "137   0.0       0.0  0.0     0.0      0.0   0.0  0.000000   0.213416      0.0   \n",
       "158   0.0       0.0  0.0     0.0      0.0   0.0  0.000000   0.000000      0.0   \n",
       "\n",
       "       anyone  ...   without  wont      work  working  worst  worth     would  \\\n",
       "156  0.000000  ...  0.237018   0.0  0.000000      0.0    0.0    0.0  0.000000   \n",
       "67   0.147387  ...  0.158264   0.0  0.000000      0.0    0.0    0.0  0.215713   \n",
       "118  0.000000  ...  0.000000   0.0  0.000000      0.0    0.0    0.0  0.000000   \n",
       "137  0.000000  ...  0.000000   0.0  0.000000      0.0    0.0    0.0  0.000000   \n",
       "158  0.130425  ...  0.000000   0.0  0.215567      0.0    0.0    0.0  0.000000   \n",
       "\n",
       "     would recommend  wouldnt  wrong  \n",
       "156              0.0      0.0    0.0  \n",
       "67               0.0      0.0    0.0  \n",
       "118              0.0      0.0    0.0  \n",
       "137              0.0      0.0    0.0  \n",
       "158              0.0      0.0    0.0  \n",
       "\n",
       "[5 rows x 337 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "156    1\n",
       "67     0\n",
       "118    1\n",
       "137    1\n",
       "158    1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_xy_train_test(train, test, bigram = False, min_df = False):\n",
    "    stpw = stopwords.words('english')\n",
    "\n",
    "    if bigram: # use training data to make vectorizer (vocabulary)\n",
    "        vectorizer = TfidfVectorizer(stop_words = stpw, ngram_range=(1,2),min_df = min_df)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(stop_words = stpw,min_df = min_df)\n",
    "    print(f'Words must appear at least in {min_df*100}% of the reviews to become feature')\n",
    "    vec = vectorizer.fit_transform(train[\"Processed\"])\n",
    "    features = pd.DataFrame(vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    test_vec = vectorizer.transform(test[\"Processed\"])\n",
    "    test_features = pd.DataFrame(test_vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "    train_merged = pd.merge(train, features, left_index = True, right_index = True).sample(frac=1) #merge data and shuffle\n",
    "    test_merged = pd.merge(test, test_features, left_index = True, right_index = True).sample(frac=1) #merge data and shuffle\n",
    "    \n",
    "    print(f'The model contains {features.shape[1]} features')\n",
    "\n",
    "    # print(\"features shape\", features.shape)\n",
    "    # print(\"test features shape\", test_features.shape)\n",
    "    # print(\"test shape\", test.shape)\n",
    "    # print(\"test merged\", test_merged.shape)\n",
    "    return [train_merged.iloc[:,3:], train_merged[\"Label\"], test_merged.iloc[:,3:], test_merged[\"Label\"]] #return [x_train, y_train,\n",
    "\n",
    "def make_countvec_xy_train_test(train, test, bigram = False, binary = False,min_df = False):\n",
    "    stpw = stopwords.words('english')\n",
    "\n",
    "    if bigram: # use training data to make vectorizer (vocabulary)\n",
    "        vectorizer = CountVectorizer(stop_words = stpw, binary=binary, ngram_range=(1,2), min_df = min_df)\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(stop_words = stpw, binary = binary, min_df = min_df)\n",
    "    print(f'Words must appear at least in {min_df*100}% of the reviews to become feature')\n",
    "\n",
    "    vec = vectorizer.fit_transform(train[\"Processed\"])\n",
    "    features = pd.DataFrame(vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    test_vec = vectorizer.transform(test[\"Processed\"])\n",
    "    test_features = pd.DataFrame(test_vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "    train_merged = pd.merge(train, features, left_index = True, right_index = True).sample(frac=1) #merge data and shuffle\n",
    "    test_merged = pd.merge(test, test_features, left_index = True, right_index = True).sample(frac=1) #merge data and shuffle\n",
    "        \n",
    "    print(f'The model contains {features.shape[1]} features')\n",
    "        \n",
    "    # print(\"features shape\", features.shape)\n",
    "    # print(\"test features shape\", test_features.shape)\n",
    "    # print(\"test shape\", test.shape)\n",
    "    # print(\"test merged\", test_merged.shape)\n",
    "    return [train_merged.iloc[:,3:], train_merged[\"Label\"], test_merged.iloc[:,3:], test_merged[\"Label\"]] #return [x_train, y_train, x_test,y_test]\n",
    "\n",
    "train_x, train_y, test_x, test_y = make_xy_train_test(train, test, min_df=0.01)\n",
    "#train_x, train_y, test_x, test_y = make_countvec_xy_train_test(train, test)\n",
    "\n",
    "#train_x, train_y = make_xy(train)\n",
    "#test_x, test_y = make_xy(test)\n",
    "\n",
    "bitrain_x, bitrain_y, bitest_x, bitest_y = make_xy_train_test(train, test, bigram=True,min_df=0.05)\n",
    "#bitrain_x, bitrain_y, bitest_x, bitest_y = make_countvec_xy_train_test(train, test, bigram=True)\n",
    "\n",
    "#bitrain_x, bitrain_y = make_xy(train, bigram = True)\n",
    "#bitest_x, bitest_y = make_xy(test, bigram = True)\n",
    "\n",
    "\n",
    "display(train_x.head())\n",
    "display(train_y.head())\n",
    "display(test_x.head())\n",
    "display(test_y.head())\n",
    "\n",
    "display(bitrain_x.head())\n",
    "display(bitrain_y.head())\n",
    "display(bitest_x.head())\n",
    "display(bitest_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "    \"\"\" Generic classifier object. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Classifier\"\n",
    "        self.esimator = None\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.estimator.predict(X_test)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        return recall, precision, accuracy, f1\n",
    "\n",
    "class NaiveBayes(Classifier):\n",
    "    \"\"\" Hyper-parameter tuning for the multinominal naive bayes classifier. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Naive Bayes\"\n",
    "        self.estimator = naive_bayes.MultinomialNB()\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        # TODO: Some feature selection needs to go here\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        print(f\"{self.name} trained with 150 features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegClassifier(Classifier):\n",
    "    \"\"\" Hyper-parameter tuning for the logistic regression classifier. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Logistic Regression\"\n",
    "        self.estimator = linear_model.LogisticRegressionCV(cv=4, max_iter=1000, Cs=[0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"training...\", end='\\r')\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        print(f\"{self.name} trained with lambda: {self.estimator.C_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeClassifier(Classifier):\n",
    "    \"\"\" Hyper-parameter tuning for the decision tree classifier. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Decision Tree\"\n",
    "        self.estimator = tree.DecisionTreeClassifier()\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"set aplhas...\", end='\\r')\n",
    "        path = self.estimator.cost_complexity_pruning_path(X_train, y_train)\n",
    "        ccp_alphas = path.ccp_alphas\n",
    "        parameters = {'ccp_alpha': ccp_alphas}\n",
    "        clf = GridSearchCV(self.estimator, parameters, cv=4)\n",
    "\n",
    "        print(\"training...\", end='\\r')\n",
    "        clf.fit(X_train, y_train)\n",
    "        self.estimator = clf.best_estimator_\n",
    "        print(f\"{self.name} trained with aplha: {self.estimator.ccp_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandForestClassifier(Classifier):\n",
    "    \"\"\" Hyper-parameter tuning for the random forest classifier. \"\"\"\n",
    "    def __init__(self, min_trees=20, max_trees=160):\n",
    "        self.name = \"Random Forest\"\n",
    "        self.estimator = ensemble.RandomForestClassifier(oob_score=True)\n",
    "        self.max_features_list = [\"auto\", \"sqrt\", \"log2\"]\n",
    "        self.n_trees = range(min_trees, max_trees, 10)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        error_rates = OrderedDict((label, []) for label in self.max_features_list)\n",
    "        min_oob_error = [None, 0, 100]\n",
    "        for label in self.max_features_list:\n",
    "            for n in self.n_trees:\n",
    "                print(f\"tuning... {label}, {n}\", end='\\r')\n",
    "                self.estimator.set_params(n_estimators=n,max_features=label)\n",
    "                self.estimator.fit(X_train, y_train)\n",
    "                oob_error = 1 - self.estimator.oob_score_\n",
    "                error_rates[label].append((n, oob_error))\n",
    "                if oob_error < min_oob_error[2]:\n",
    "                    min_oob_error = [label, n, oob_error]\n",
    "\n",
    "        print(\"training...\", end='\\r')\n",
    "        self.estimator.set_params(n_estimators=min_oob_error[1],max_features=min_oob_error[0])\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        print(f\"{self.name} trained with hyper-parameters: {self.estimator.n_estimators}, {self.estimator.max_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score, accuracy_score,f1_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words must appear at least in 1.0% of the reviews to become feature\n",
      "The model contains 1255 features\n",
      "Naive Bayes trained\n",
      "Logistic Regression trained with lambda: [10.]\n",
      "Decision Tree trained with aplha: 0.016480530741049437\n",
      "tuning... auto, 30\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Documents\\Python\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:540: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\franc\\Documents\\Python\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest trained with hyper-parameters: 130, sqrt\n",
      "unigram | tfidf:\n",
      "           Naive Bayes  Logistic Regression  Decision Tree  Random Forest\n",
      "recall        0.837500             0.875000       0.725000       0.900000\n",
      "precision     0.893333             0.823529       0.630435       0.818182\n",
      "accuracy      0.868750             0.843750       0.650000       0.850000\n",
      "f1            0.864516             0.848485       0.674419       0.857143\n",
      "Words must appear at least in 1.0% of the reviews to become feature\n",
      "The model contains 1255 features\n",
      "Naive Bayes trained\n",
      "Logistic Regression trained with lambda: [10.]\n",
      "Decision Tree trained with aplha: 0.010713206998389069\n",
      "Random Forest trained with hyper-parameters: 120, sqrt\n",
      "unigram | countvec:\n",
      "           Naive Bayes  Logistic Regression  Decision Tree  Random Forest\n",
      "recall          0.8625             0.837500       0.725000       0.825000\n",
      "precision       0.8625             0.797619       0.637363       0.795181\n",
      "accuracy        0.8625             0.812500       0.656250       0.806250\n",
      "f1              0.8625             0.817073       0.678363       0.809816\n",
      "Words must appear at least in 1.0% of the reviews to become feature\n",
      "The model contains 1255 features\n",
      "Naive Bayes trained\n",
      "Logistic Regression trained with lambda: [0.01]\n",
      "Decision Tree trained with aplha: 0.013393942914681906\n",
      "tuning... auto, 30\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Documents\\Python\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:540: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\franc\\Documents\\Python\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest trained with hyper-parameters: 140, sqrt\n",
      "unigram | binary:\n",
      "           Naive Bayes  Logistic Regression  Decision Tree  Random Forest\n",
      "recall            0.85             0.887500       0.650000       0.762500\n",
      "precision         0.85             0.755319       0.641975       0.824324\n",
      "accuracy          0.85             0.800000       0.643750       0.800000\n",
      "f1                0.85             0.816092       0.645963       0.792208\n"
     ]
    }
   ],
   "source": [
    "def run_models(bigram = False, vec_type = \"tfidf\", min_df = False):\n",
    "    train = pd.read_csv(\"./train.csv\")\n",
    "    test = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "\n",
    "    if vec_type == \"tfidf\":\n",
    "        train_x, train_y, test_x, test_y = make_xy_train_test(train, test, bigram, min_df =  min_df)\n",
    "    elif vec_type == \"countvec\":\n",
    "        train_x, train_y, test_x, test_y = make_countvec_xy_train_test(train, test, bigram,min_df =  min_df)\n",
    "    elif vec_type == \"binary\":\n",
    "        train_x, train_y, test_x, test_y = make_countvec_xy_train_test(train, test, bigram, binary=True,min_df =  min_df)\n",
    "    \n",
    "    data = {}\n",
    "    classifiers = [NaiveBayes(), LogRegClassifier(), TreeClassifier(), RandForestClassifier()]\n",
    "    \n",
    "    #feature selection for naiveBayes\n",
    "    for clf in classifiers:\n",
    "        if clf == NaiveBayes(): #select n most important features and use them for train the classifier\n",
    "            \n",
    "            #choose the number of features\n",
    "            #n_feat=np.shape(train_x)[1]\n",
    "            n_feat = 150\n",
    "            \n",
    "            print(\"Extracting %d best features by a chi-squared test\" %n_feat)\n",
    "            ch2 = SelectKBest(mutual_info_regression, k=n_feat)\n",
    "            train_x = ch2.fit_transform(train_x, train_y)\n",
    "            test_x = ch2.transform(test_x)\n",
    "            \n",
    "        clf.train(train_x, train_y)\n",
    "        data[clf.name] = clf.evaluate(test_x, test_y)\n",
    "    df = pd.DataFrame(data, \\\n",
    "        columns=[clf.name for clf in classifiers], \\\n",
    "        index=[\"recall\", \"precision\", \"accuracy\", \"f1\"])\n",
    "    print(f'{\"bigram\" if bigram else \"unigram\"} | {vec_type}:')\n",
    "    print(df)\n",
    "\n",
    "run_models(vec_type=\"tfidf\",bigram=False, min_df = 0.01)        \n",
    "run_models(vec_type=\"countvec\", bigram=False, min_df = 0.01)\n",
    "run_models(vec_type=\"binary\", bigram=False, min_df = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words must appear at least in 1.0% of the reviews to become feature\n",
      "The model contains 1255 features\n",
      "Extracting 10 best features by a chi-squared test\n",
      "chicago\n",
      "decided\n",
      "elevators\n",
      "great\n",
      "location\n",
      "luxury\n",
      "millennium\n",
      "priceline\n",
      "recently\n",
      "smell\n",
      "Extracting 10 best features by logistic regression coefficients:\n",
      "10 best features pointing towards fake reviews:\n",
      "Feature: chicago, Score: -0.00582\n",
      "Feature: smell, Score: -0.00260\n",
      "Feature: finally, Score: -0.00251\n",
      "Feature: luxury, Score: -0.00250\n",
      "Feature: hotel, Score: -0.00243\n",
      "Feature: recently, Score: -0.00238\n",
      "Feature: room, Score: -0.00236\n",
      "Feature: experience, Score: -0.00229\n",
      "Feature: seemed, Score: -0.00229\n",
      "10 best features pointing towards true reviews:\n",
      "Feature: location, Score: 0.00323\n",
      "Feature: great, Score: 0.00319\n",
      "Feature: floor, Score: 0.00227\n",
      "Feature: star, Score: 0.00216\n",
      "Feature: elevators, Score: 0.00202\n",
      "Feature: construction, Score: 0.00179\n",
      "Feature: open, Score: 0.00176\n",
      "Feature: elevator, Score: 0.00174\n",
      "Feature: th, Score: 0.00163\n"
     ]
    }
   ],
   "source": [
    "def best_feat(k,bigram = False, vec_type = \"tfidf\", min_df = False):\n",
    "    train = pd.read_csv(\"./train.csv\")\n",
    "    test = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "\n",
    "    if vec_type == \"tfidf\":\n",
    "        train_x, train_y, test_x, test_y = make_xy_train_test(train, test, bigram, min_df =  min_df)\n",
    "    elif vec_type == \"countvec\":\n",
    "        train_x, train_y, test_x, test_y = make_countvec_xy_train_test(train, test, bigram,min_df =  min_df)\n",
    "    elif vec_type == \"binary\":\n",
    "        train_x, train_y, test_x, test_y = make_countvec_xy_train_test(train, test, bigram, binary=True,min_df =  min_df)\n",
    "       \n",
    "    feature_names = train_x.columns\n",
    "\n",
    "    #Extracting k best features by a a chi-squared test\n",
    "\n",
    "    print(\"Extracting %d best features by a chi-squared test\" %k)\n",
    "    ch2 = SelectKBest(chi2, k=k)\n",
    "    ch2.fit(train_x, train_y)\n",
    "    feature_names_chi2 = [feature_names[i] for i in ch2.get_support(indices=True)]\n",
    "    \n",
    "    for col in feature_names_chi2: \n",
    "        print(col) \n",
    "      \n",
    "    \n",
    "    #Extracting k best features by logistic regression coefficients:\n",
    "    \n",
    "    # define the model\n",
    "    model = linear_model.LogisticRegressionCV(cv=4, max_iter=1000, Cs=[0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "    # fit the model\n",
    "    model.fit(train_x, train_y)\n",
    "    # get importance\n",
    "    importance = model.coef_[0]\n",
    "    index = np.argsort(importance)\n",
    "    n=np.shape(index)[0]\n",
    "    # summarize feature importance\n",
    "    print(\"Extracting %d best features by logistic regression coefficients:\" %k)\n",
    "    print(\"%d best features pointing towards fake reviews:\" %k)\n",
    "    for i in range(0,9):\n",
    "        print('Feature: %s, Score: %.5f' %(feature_names[index[i]], importance[index[i]]))\n",
    "        \n",
    "    print(\"%d best features pointing towards true reviews:\" %k)\n",
    "\n",
    "    for i in range(0,9):\n",
    "        print('Feature: %s, Score: %.5f' %(feature_names[index[n-i-1]], importance[index[n-i-1]]))\n",
    "\n",
    "best_feat(10,bigram = False, vec_type = \"tfidf\", min_df = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
