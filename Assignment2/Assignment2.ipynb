{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SETUP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import os"
   ]
  },
  {
   "source": [
    "# Read data\n",
    "def readReviews(path):\n",
    "    reviews = []\n",
    "    for fold in range(1,6):\n",
    "        foldData = []\n",
    "        for filename in glob.glob(os.path.join(f'{path}/fold{fold}/', '*.txt')):\n",
    "            file = open(filename)\n",
    "            foldData.append(file.read())\n",
    "        reviews.append(foldData)\n",
    "    return reviews\n",
    "\n",
    "NT = readReviews(\"./op_spam_v1.4/negative_polarity/truthful_from_Web\")\n",
    "ND = readReviews(\"./op_spam_v1.4/negative_polarity/deceptive_from_MTurk\")\n",
    "# PT = readReviews(\"./op_spam_v1.4/positive_polarity/truthful_from_TripAdvisor\")\n",
    "# PD = readReviews(\"./op_spam_v1.4/positive_polarity/deceptive_from_MTurk\")\n",
    "\n",
    "#create test and train\n",
    "NTtrain = sum(NT[0:4], [])\n",
    "NDtrain = sum(ND[0:4], [])\n",
    "test = NT[4]\n",
    "\n",
    "#clean data/feature selection\n",
    "\n",
    "# Folds:\n",
    "# 1-4 (640 reviews) for training and hyper-parameter tuning\n",
    "# Fold 5 (160 reviews) is used to estimate the performance of the classifiers that were selected on the training set\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 100,
   "outputs": []
  },
  {
   "source": [
    "# Analysis\n",
    "Use cross-validation or (for random forests) out-of-bag evaluation to select the values of the hyper-parameters of the algorithms on the training set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Multinomial naive Bayes (generative linear classifier)\n",
    "For naive Bayes, the performance might be improved by applying some form of feature selection (in addition to removing the sparse terms)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Regularized logistic regression (discriminative linear classifier)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Classification trees, (flexible classifier)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Random forests (flexible classifier)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Model accuracy comparison analysis\n",
    "Comparisons of the accuracy of different models should be supported by a statistical test. For the comparison of the other quality measures (precision, recall, F1 score), a statistical test is not required."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}