{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('3.8.5')",
   "display_name": "Python 3.8.5 64-bit ('3.8.5')",
   "metadata": {
    "interpreter": {
     "hash": "7b02b8ae5267e70a0243ab4ec273717906af0148309b548a65b054fdc3fc7816"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SETUP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(path, fold_nrs, label):\n",
    "    columns = ['Raw', 'Processed', 'Label']\n",
    "    df = pd.DataFrame()\n",
    "    for i in fold_nrs:\n",
    "        fold = \"fold\"+str(i)\n",
    "        p = path + fold\n",
    "        for file in os.listdir(p): # for each .txt file in this fold's folder\n",
    "            if file.endswith(\".txt\"):\n",
    "                f = open(os.path.join(p, file), \"r\")\n",
    "                review = f.read()\n",
    "                # remove whitespaces, numbers, punctuation, & make lowercase\n",
    "                processed = process_string(review)\n",
    "                new_row = pd.DataFrame([[review, processed, label]])\n",
    "                df = df.append(new_row)\n",
    "    df.columns = columns\n",
    "    return df\n",
    "\n",
    "def make_train_test_set():\n",
    "    # Focusing only on the negative reviews\n",
    "    path_dec = \"./op_spam_v1.4/negative_polarity/deceptive_from_MTurk/\"\n",
    "    path_true = \"./op_spam_v1.4/negative_polarity/truthful_from_Web/\"\n",
    "\n",
    "    # Label = 1 if it is a truthful (negative) review, =0 if it is a deceptive (negative) review\n",
    "\n",
    "    #loading training set:\n",
    "    train_dec = load_reviews(path_dec, np.arange(4)+1, 0) # folds 1-4 form the training set\n",
    "    train_true = load_reviews(path_true, np.arange(4)+1, 1)\n",
    "    train = pd.concat([train_dec, train_true])\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    #loading the test set:\n",
    "    test_dec = load_reviews(path_dec, [5], 0)  # test set for deceptive reviews\n",
    "    test_true = load_reviews(path_true, [5], 1)\n",
    "    test = pd.concat([test_dec, test_true])\n",
    "    test = test.reset_index(drop=True)\n",
    "\n",
    "    return [train,test]\n",
    "\n",
    "def process_string(s):\n",
    "    s = s.strip()    # remove whitespaces\n",
    "    s = s.lower() # to lowercase\n",
    "    s = re.sub(r'\\d+', '', s) # remove numbers\n",
    "    s = s.translate(str.maketrans(\"\",\"\", string.punctuation)) # remove punctuation\n",
    "    return s\n",
    "\n",
    "\n",
    "##########################\n",
    "###Process files to CSV###\n",
    "##########################\n",
    "\n",
    "# train, test = make_train_test_set()\n",
    "# train.to_csv(\"./train.csv\", header = ['Raw', 'Processed', 'Label'], index=False)\n",
    "# test.to_csv(\"./test.csv\", header = ['Raw', 'Processed', 'Label'], index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n Shape of training set: (640, 3)\n                                                 Raw  ... Label\n0  My husband and I stayed at the Sofitel Chicago...  ...     0\n1  Staying at the Sofitel was one of the less ple...  ...     0\n2  I stayed at Sofitel with my husband for a week...  ...     0\n3  I stayed at the Sofitel Chicago Water Tower ho...  ...     0\n4  After arriving at the Sofitel Chicago Water To...  ...     0\n\n[5 rows x 3 columns]\n\n Shape of test set: (160, 3)\n                                                 Raw  ... Label\n0  I stayed at the InterContinental in Chicago fo...  ...     0\n1  I have to agree that the InterContinental Chic...  ...     0\n2  Upon entering my hotel room at The Palmer Hous...  ...     0\n3  We will not be back to this hotel. There are s...  ...     0\n4  The Intercontinental Chicago Magnificent Mile ...  ...     0\n\n[5 rows x 3 columns]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 Raw  ... Label\n",
       "0  My husband and I stayed at the Sofitel Chicago...  ...     0\n",
       "1  Staying at the Sofitel was one of the less ple...  ...     0\n",
       "2  I stayed at Sofitel with my husband for a week...  ...     0\n",
       "3  I stayed at the Sofitel Chicago Water Tower ho...  ...     0\n",
       "4  After arriving at the Sofitel Chicago Water To...  ...     0\n",
       "\n",
       "[5 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Raw</th>\n      <th>Processed</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My husband and I stayed at the Sofitel Chicago...</td>\n      <td>my husband and i stayed at the sofitel chicago...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Staying at the Sofitel was one of the less ple...</td>\n      <td>staying at the sofitel was one of the less ple...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I stayed at Sofitel with my husband for a week...</td>\n      <td>i stayed at sofitel with my husband for a week...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I stayed at the Sofitel Chicago Water Tower ho...</td>\n      <td>i stayed at the sofitel chicago water tower ho...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>After arriving at the Sofitel Chicago Water To...</td>\n      <td>after arriving at the sofitel chicago water to...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"\\n Shape of training set: {train.shape}\")\n",
    "print(train.head())\n",
    "print(f\"\\n Shape of test set: {test.shape}\")\n",
    "print(test.head())\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tfidf_word(data, stopwords = None):\n",
    "    vectorizer = TfidfVectorizer(stop_words = stopwords)\n",
    "    vec = vectorizer.fit_transform(data)\n",
    "    return pd.DataFrame(vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "def Tfidf_bigram(data, stopwords = None):\n",
    "    vectorizer = TfidfVectorizer(stop_words = stopwords, ngram_range=(2,2))\n",
    "    vec = vectorizer.fit_transform(data)\n",
    "    return pd.DataFrame(vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "def make_xy(data, bigram = False):\n",
    "    if bigram:\n",
    "        features = Tfidf_bigram(data[\"Processed\"], stopwords = stopwords.words('english'))    \n",
    "    else:\n",
    "        features = Tfidf_word(data[\"Processed\"], stopwords = stopwords.words('english'))\n",
    "    merged = pd.merge(data, features, left_index = True, right_index = True).sample(frac=1) #merge data and shuffle\n",
    "    return merged.iloc[:,3:], merged[\"Label\"] #return x and y\n",
    "\n",
    "train_x, train_y = make_xy(train)\n",
    "test_x, test_y = make_xy(test)\n",
    "\n",
    "bitrain_x, bitrain_y = make_xy(train, bigram = True)\n",
    "bitest_x, bitest_y = make_xy(test, bigram = True)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Analysis\n",
    "Use cross-validation or (for random forests) out-of-bag evaluation to select the values of the hyper-parameters of the algorithms on the training set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Multinomial naive Bayes (generative linear classifier)\n",
    "For naive Bayes, the performance might be improved by applying some form of feature selection (in addition to removing the sparse terms)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Regularized logistic regression (discriminative linear classifier)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Classification trees, (flexible classifier)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Random forests (flexible classifier)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Model accuracy comparison analysis\n",
    "Comparisons of the accuracy of different models should be supported by a statistical test. For the comparison of the other quality measures (precision, recall, F1 score), a statistical test is not required."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}