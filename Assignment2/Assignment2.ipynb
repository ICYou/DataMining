{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jsiu/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from IPython.display import display\n",
    "from sklearn import naive_bayes, linear_model, tree, ensemble\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, mutual_info_regression\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(path, fold_nrs, label):\n",
    "    columns = ['Raw', 'Processed', 'Label']\n",
    "    df = pd.DataFrame()\n",
    "    for i in fold_nrs:\n",
    "        fold = \"fold\"+str(i)\n",
    "        p = path + fold\n",
    "        for file in os.listdir(p): # for each .txt file in this fold's folder\n",
    "            if file.endswith(\".txt\"):\n",
    "                f = open(os.path.join(p, file), \"r\")\n",
    "                review = f.read()\n",
    "                # remove whitespaces, numbers, punctuation, & make lowercase\n",
    "                processed = process_string(review)\n",
    "                new_row = pd.DataFrame([[review, processed, label]])\n",
    "                df = df.append(new_row)\n",
    "    df.columns = columns\n",
    "    return df\n",
    "\n",
    "def make_train_test_set():\n",
    "    # Focusing only on the negative reviews\n",
    "    path_dec = \"./op_spam_v1.4/negative_polarity/deceptive_from_MTurk/\"\n",
    "    path_true = \"./op_spam_v1.4/negative_polarity/truthful_from_Web/\"\n",
    "\n",
    "    # Label = 1 if it is a truthful (negative) review, =0 if it is a deceptive (negative) review\n",
    "\n",
    "    #loading training set:\n",
    "    train_dec = load_reviews(path_dec, np.arange(4)+1, 0) # folds 1-4 form the training set\n",
    "    train_true = load_reviews(path_true, np.arange(4)+1, 1)\n",
    "    train = pd.concat([train_dec, train_true])\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    #testchangeDELTETHIS\n",
    "    #loading the test set:\n",
    "    test_dec = load_reviews(path_dec, [5], 0)  # test set for deceptive reviews\n",
    "    test_true = load_reviews(path_true, [5], 1)\n",
    "    test = pd.concat([test_dec, test_true])\n",
    "    test = test.reset_index(drop=True)\n",
    "\n",
    "    return [train,test]\n",
    "\n",
    "def process_string(s):\n",
    "    s = s.strip()    # remove whitespaces\n",
    "    s = s.lower() # to lowercase\n",
    "    s = re.sub(r'\\d+', '', s) # remove numbers\n",
    "    s = s.translate(str.maketrans(\"\",\"\", string.punctuation)) # remove punctuation\n",
    "    return s\n",
    "\n",
    "\n",
    "##########################\n",
    "###Process files to CSV###\n",
    "##########################\n",
    "\n",
    "# train, test = make_train_test_set()\n",
    "# train.to_csv(\"./train.csv\", header = ['Raw', 'Processed', 'Label'], index=False)\n",
    "# test.to_csv(\"./test.csv\", header = ['Raw', 'Processed', 'Label'], index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n Shape of training set: (640, 3)\n                                                 Raw  \\\n0  My husband and I stayed at the Sofitel Chicago...   \n1  Staying at the Sofitel was one of the less ple...   \n2  I stayed at Sofitel with my husband for a week...   \n3  I stayed at the Sofitel Chicago Water Tower ho...   \n4  After arriving at the Sofitel Chicago Water To...   \n\n                                           Processed  Label  \n0  my husband and i stayed at the sofitel chicago...      0  \n1  staying at the sofitel was one of the less ple...      0  \n2  i stayed at sofitel with my husband for a week...      0  \n3  i stayed at the sofitel chicago water tower ho...      0  \n4  after arriving at the sofitel chicago water to...      0  \n\n Shape of test set: (160, 3)\n                                                 Raw  \\\n0  I stayed at the InterContinental in Chicago fo...   \n1  I have to agree that the InterContinental Chic...   \n2  Upon entering my hotel room at The Palmer Hous...   \n3  We will not be back to this hotel. There are s...   \n4  The Intercontinental Chicago Magnificent Mile ...   \n\n                                           Processed  Label  \n0  i stayed at the intercontinental in chicago fo...      0  \n1  i have to agree that the intercontinental chic...      0  \n2  upon entering my hotel room at the palmer hous...      0  \n3  we will not be back to this hotel there are se...      0  \n4  the intercontinental chicago magnificent mile ...      0  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 Raw  \\\n",
       "0  My husband and I stayed at the Sofitel Chicago...   \n",
       "1  Staying at the Sofitel was one of the less ple...   \n",
       "2  I stayed at Sofitel with my husband for a week...   \n",
       "3  I stayed at the Sofitel Chicago Water Tower ho...   \n",
       "4  After arriving at the Sofitel Chicago Water To...   \n",
       "\n",
       "                                           Processed  Label  \n",
       "0  my husband and i stayed at the sofitel chicago...      0  \n",
       "1  staying at the sofitel was one of the less ple...      0  \n",
       "2  i stayed at sofitel with my husband for a week...      0  \n",
       "3  i stayed at the sofitel chicago water tower ho...      0  \n",
       "4  after arriving at the sofitel chicago water to...      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Raw</th>\n      <th>Processed</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My husband and I stayed at the Sofitel Chicago...</td>\n      <td>my husband and i stayed at the sofitel chicago...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Staying at the Sofitel was one of the less ple...</td>\n      <td>staying at the sofitel was one of the less ple...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I stayed at Sofitel with my husband for a week...</td>\n      <td>i stayed at sofitel with my husband for a week...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I stayed at the Sofitel Chicago Water Tower ho...</td>\n      <td>i stayed at the sofitel chicago water tower ho...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>After arriving at the Sofitel Chicago Water To...</td>\n      <td>after arriving at the sofitel chicago water to...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"\\n Shape of training set: {train.shape}\")\n",
    "print(train.head())\n",
    "print(f\"\\n Shape of test set: {test.shape}\")\n",
    "print(test.head())\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   aaa  aaahed  aback  abassador  ability  able  abound  abrupt  absence  \\\n0    0       0      0          0        0     0       0       0        0   \n1    0       0      0          0        0     0       0       0        0   \n2    0       0      0          0        0     0       0       0        0   \n3    0       0      0          0        0     0       0       0        0   \n4    0       0      0          0        0     0       0       0        0   \n\n   absent  ...  youre  youth  youve  yrs  yuck  yummy  yunan  yup  zone  zoo  \n0       0  ...      0      0      0    0     0      0      0    0     0    0  \n1       0  ...      0      0      0    0     0      0      0    0     0    0  \n2       0  ...      0      0      0    0     0      0      0    0     0    0  \n3       0  ...      0      0      0    0     0      0      0    0     0    0  \n4       0  ...      0      0      0    0     0      0      0    0     0    0  \n\n[5 rows x 6955 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>aaahed</th>\n      <th>aback</th>\n      <th>abassador</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>abound</th>\n      <th>abrupt</th>\n      <th>absence</th>\n      <th>absent</th>\n      <th>...</th>\n      <th>youre</th>\n      <th>youth</th>\n      <th>youve</th>\n      <th>yrs</th>\n      <th>yuck</th>\n      <th>yummy</th>\n      <th>yunan</th>\n      <th>yup</th>\n      <th>zone</th>\n      <th>zoo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 6955 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0    0\n1    0\n2    0\n3    0\n4    0\nName: Label, dtype: int64"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   aaa  aaahed  aback  abassador  ability  able  abound  abrupt  absence  \\\n0    0       0      0          0        0     1       0       0        0   \n1    0       0      0          0        0     0       0       0        0   \n2    0       0      0          0        0     1       0       0        0   \n3    0       0      0          0        0     0       0       0        0   \n4    0       0      0          0        0     0       0       0        0   \n\n   absent  ...  youre  youth  youve  yrs  yuck  yummy  yunan  yup  zone  zoo  \n0       0  ...      0      0      0    0     0      0      0    0     0    0  \n1       0  ...      0      0      0    0     0      0      0    0     0    0  \n2       0  ...      0      0      0    0     0      0      0    0     0    0  \n3       0  ...      0      0      0    0     0      0      0    0     0    0  \n4       0  ...      0      0      0    0     0      0      0    0     0    0  \n\n[5 rows x 6955 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>aaahed</th>\n      <th>aback</th>\n      <th>abassador</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>abound</th>\n      <th>abrupt</th>\n      <th>absence</th>\n      <th>absent</th>\n      <th>...</th>\n      <th>youre</th>\n      <th>youth</th>\n      <th>youve</th>\n      <th>yrs</th>\n      <th>yuck</th>\n      <th>yummy</th>\n      <th>yunan</th>\n      <th>yup</th>\n      <th>zone</th>\n      <th>zoo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 6955 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0    0\n1    0\n2    0\n3    0\n4    0\nName: Label, dtype: int64"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   aaa  aaa one  aaahed  aaahed picture  aback  aback phone  abassador  \\\n0    0        0       0               0      0            0          0   \n1    0        0       0               0      0            0          0   \n2    0        0       0               0      0            0          0   \n3    0        0       0               0      0            0          0   \n4    0        0       0               0      0            0          0   \n\n   abassador east  abassador future  ability  ...  yunan  yunan didnt  yup  \\\n0               0                 0        0  ...      0            0    0   \n1               0                 0        0  ...      0            0    0   \n2               0                 0        0  ...      0            0    0   \n3               0                 0        0  ...      0            0    0   \n4               0                 0        0  ...      0            0    0   \n\n   yup even  yup got  zone  zone computer  zone would  zoo  zoo second  \n0         0        0     0              0           0    0           0  \n1         0        0     0              0           0    0           0  \n2         0        0     0              0           0    0           0  \n3         0        0     0              0           0    0           0  \n4         0        0     0              0           0    0           0  \n\n[5 rows x 49391 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>aaa one</th>\n      <th>aaahed</th>\n      <th>aaahed picture</th>\n      <th>aback</th>\n      <th>aback phone</th>\n      <th>abassador</th>\n      <th>abassador east</th>\n      <th>abassador future</th>\n      <th>ability</th>\n      <th>...</th>\n      <th>yunan</th>\n      <th>yunan didnt</th>\n      <th>yup</th>\n      <th>yup even</th>\n      <th>yup got</th>\n      <th>zone</th>\n      <th>zone computer</th>\n      <th>zone would</th>\n      <th>zoo</th>\n      <th>zoo second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 49391 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0    0\n1    0\n2    0\n3    0\n4    0\nName: Label, dtype: int64"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   aaa  aaa one  aaahed  aaahed picture  aback  aback phone  abassador  \\\n0    0        0       0               0      0            0          0   \n1    0        0       0               0      0            0          0   \n2    0        0       0               0      0            0          0   \n3    0        0       0               0      0            0          0   \n4    0        0       0               0      0            0          0   \n\n   abassador east  abassador future  ability  ...  yunan  yunan didnt  yup  \\\n0               0                 0        0  ...      0            0    0   \n1               0                 0        0  ...      0            0    0   \n2               0                 0        0  ...      0            0    0   \n3               0                 0        0  ...      0            0    0   \n4               0                 0        0  ...      0            0    0   \n\n   yup even  yup got  zone  zone computer  zone would  zoo  zoo second  \n0         0        0     0              0           0    0           0  \n1         0        0     0              0           0    0           0  \n2         0        0     0              0           0    0           0  \n3         0        0     0              0           0    0           0  \n4         0        0     0              0           0    0           0  \n\n[5 rows x 49391 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>aaa one</th>\n      <th>aaahed</th>\n      <th>aaahed picture</th>\n      <th>aback</th>\n      <th>aback phone</th>\n      <th>abassador</th>\n      <th>abassador east</th>\n      <th>abassador future</th>\n      <th>ability</th>\n      <th>...</th>\n      <th>yunan</th>\n      <th>yunan didnt</th>\n      <th>yup</th>\n      <th>yup even</th>\n      <th>yup got</th>\n      <th>zone</th>\n      <th>zone computer</th>\n      <th>zone would</th>\n      <th>zoo</th>\n      <th>zoo second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 49391 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0    0\n1    0\n2    0\n3    0\n4    0\nName: Label, dtype: int64"
     },
     "metadata": {}
    }
   ],
   "source": [
    "def make_xy_train_test(train, test, bigram = False, min_df = False):\n",
    "    stpw = stopwords.words('english')\n",
    "\n",
    "    if bigram: # use training data to make vectorizer (vocabulary)\n",
    "        vectorizer = TfidfVectorizer(stop_words = stpw, ngram_range=(1,2), min_df=min_df)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(stop_words = stpw, min_df=min_df)\n",
    "        \n",
    "    vec = vectorizer.fit_transform(train[\"Processed\"])\n",
    "    features = pd.DataFrame(vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    test_vec = vectorizer.transform(test[\"Processed\"])\n",
    "    test_features = pd.DataFrame(test_vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "    train_merged = pd.merge(train, features, left_index = True, right_index = True)#.sample(frac=1) #merge data and shuffle\n",
    "    test_merged = pd.merge(test, test_features, left_index = True, right_index = True)#.sample(frac=1) #merge data and shuffle\n",
    "\n",
    "    return [train_merged.iloc[:,3:], train_merged[\"Label\"], test_merged.iloc[:,3:], test_merged[\"Label\"]] #return [x_train, y_train,\n",
    "\n",
    "def make_countvec_xy_train_test(train, test, bigram = False, binary = False, min_df = False):\n",
    "    stpw = stopwords.words('english')\n",
    "\n",
    "    if bigram: # use training data to make vectorizer (vocabulary)\n",
    "        vectorizer = CountVectorizer(stop_words = stpw, binary=binary, ngram_range=(1,2), min_df=min_df)\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(stop_words = stpw, binary = binary, min_df=min_df)\n",
    "\n",
    "    vec = vectorizer.fit_transform(train[\"Processed\"])\n",
    "    features = pd.DataFrame(vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    test_vec = vectorizer.transform(test[\"Processed\"])\n",
    "    test_features = pd.DataFrame(test_vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "    train_merged = pd.merge(train, features, left_index = True, right_index = True)#.sample(frac=1) #merge data and shuffle\n",
    "    test_merged = pd.merge(test, test_features, left_index = True, right_index = True)#.sample(frac=1) #merge data and shuffle\n",
    "\n",
    "    # print(\"features shape\", features.shape)\n",
    "    # print(\"test features shape\", test_features.shape)\n",
    "    # print(\"test shape\", test.shape)\n",
    "    # print(\"test merged\", test_merged.shape)\n",
    "    return [train_merged.iloc[:,3:], train_merged[\"Label\"], test_merged.iloc[:,3:], test_merged[\"Label\"]] #return [x_train, y_train,\n",
    "\n",
    "#train_x, train_y, test_x, test_y = make_countvec_xy_train_test(train, test)\n",
    "train_x, train_y, test_x, test_y = make_countvec_xy_train_test(train, test, bigram=False)\n",
    "\n",
    "bitrain_x, bitrain_y, bitest_x, bitest_y = make_countvec_xy_train_test(train, test, bigram=True)\n",
    "\n",
    "display(train_x.head())\n",
    "display(train_y.head())\n",
    "display(test_x.head())\n",
    "display(test_y.head())\n",
    "\n",
    "display(bitrain_x.head())\n",
    "display(bitrain_y.head())\n",
    "display(bitest_x.head())\n",
    "display(bitest_y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Use cross-validation or (for random forests) out-of-bag evaluation to select the values of the hyper-parameters of the algorithms on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial naive Bayes (generative linear classifier)\n",
    "For naive Bayes, the performance might be improved by applying some form of feature selection (in addition to removing the sparse terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "    \"\"\" Generic classifier object. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Classifier\"\n",
    "        self.esimator = None\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.name == \"Naive Bayes\":\n",
    "            X_test = self.ch2.transform(X_test)\n",
    "        \n",
    "        y_pred = self.estimator.predict(X_test)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        return y_pred, (recall, precision, accuracy, f1)\n",
    "\n",
    "class NaiveBayes(Classifier):\n",
    "    \"\"\" Hyper-parameter tuning for the multinominal naive bayes classifier. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Naive Bayes\"\n",
    "        self.estimator = naive_bayes.MultinomialNB()\n",
    "        self.n_feat = 150\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        n_feats = [140, 150, 160, 1000, 1255]\n",
    "        scores = []\n",
    "        for n_feat in n_feats:\n",
    "            print(f\"Extracting {n_feat} best features by a chi-squared test\", end='\\r')\n",
    "            ch2 = SelectKBest(mutual_info_regression, k=n_feat)\n",
    "            train_x = ch2.fit_transform(X_train, y_train)\n",
    "            scores.append(self.cross_validate(train_x, y_train))\n",
    "        \n",
    "        self.n_feat = n_feats[scores.index(max(scores))]\n",
    "        self.ch2 = SelectKBest(mutual_info_regression, k=self.n_feat)\n",
    "        X_train = self.ch2.fit_transform(X_train, y_train)\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        print(f\"{self.name} trained with {self.n_feat} features\")\n",
    "\n",
    "    def cross_validate(self, X_train, y_train):\n",
    "        accuracy_scores = []\n",
    "        kf = KFold(n_splits=4)\n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            train_x, test_x = X_train[train_index], X_train[test_index]\n",
    "            train_y, test_y = y_train[train_index], y_train[test_index]\n",
    "            self.estimator.fit(train_x, train_y)\n",
    "            accuracy_scores.append(self.estimator.score(test_x, test_y))\n",
    "\n",
    "        return np.mean(accuracy_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression (discriminative linear classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegClassifier(Classifier):\n",
    "    \"\"\" Hyper-parameter tuning for the logistic regression classifier. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Logistic Regression\"\n",
    "        self.estimator = linear_model.LogisticRegressionCV(cv=4, max_iter=1000, Cs=[0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"training...\", end='\\r')\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        print(f\"{self.name} trained with lambda: {self.estimator.C_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification trees, (flexible classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeClassifier(Classifier):\n",
    "    \"\"\" Hyper-parameter tuning for the decision tree classifier. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Decision Tree\"\n",
    "        self.estimator = tree.DecisionTreeClassifier()\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"set aplhas...\", end='\\r')\n",
    "        path = self.estimator.cost_complexity_pruning_path(X_train, y_train)\n",
    "        ccp_alphas = path.ccp_alphas\n",
    "        parameters = {'ccp_alpha': ccp_alphas}\n",
    "        clf = GridSearchCV(self.estimator, parameters, cv=4)\n",
    "\n",
    "        print(\"training...\", end='\\r')\n",
    "        clf.fit(X_train, y_train)\n",
    "        self.estimator = clf.best_estimator_\n",
    "        print(f\"{self.name} trained with aplha: {self.estimator.ccp_alpha}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests (flexible classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandForestClassifier(Classifier):\n",
    "    \"\"\" Hyper-parameter tuning for the random forest classifier. \"\"\"\n",
    "    def __init__(self, min_trees=20, max_trees=160):\n",
    "        self.name = \"Random Forest\"\n",
    "        self.estimator = ensemble.RandomForestClassifier(oob_score=True)\n",
    "        self.max_features_list = [\"auto\", \"sqrt\", \"log2\"]\n",
    "        self.n_trees = range(min_trees, max_trees, 10)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        error_rates = OrderedDict((label, []) for label in self.max_features_list)\n",
    "        min_oob_error = [None, 0, 100]\n",
    "        for label in self.max_features_list:\n",
    "            for n in self.n_trees:\n",
    "                print(f\"tuning... {label}, {n}\", end='\\r')\n",
    "                self.estimator.set_params(n_estimators=n,max_features=label)\n",
    "                self.estimator.fit(X_train, y_train)\n",
    "                oob_error = 1 - self.estimator.oob_score_\n",
    "                error_rates[label].append((n, oob_error))\n",
    "                if oob_error < min_oob_error[2]:\n",
    "                    min_oob_error = [label, n, oob_error]\n",
    "\n",
    "        print(\"training...\", end='\\r')\n",
    "        self.estimator.set_params(n_estimators=min_oob_error[1],max_features=min_oob_error[0])\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        print(f\"{self.name} trained with hyper-parameters: {self.estimator.n_estimators}, {self.estimator.max_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy comparison analysis\n",
    "Comparisons of the accuracy of different models should be supported by a statistical test. For the comparison of the other quality measures (precision, recall, F1 score), a statistical test is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Naive Bayes trained with 1255 features\n",
      "Logistic Regression trained with lambda: [10.]\n",
      "Decision Tree trained with aplha: 0.019087865218129996\n",
      "Random Forest trained with hyper-parameters: 140, log2\n",
      "unigram | tfidf:\n",
      "           Naive Bayes  Logistic Regression  Decision Tree  Random Forest\n",
      "recall        0.837500             0.875000       0.725000       0.800000\n",
      "precision     0.893333             0.823529       0.630435       0.864865\n",
      "accuracy      0.868750             0.843750       0.650000       0.837500\n",
      "f1            0.864516             0.848485       0.674419       0.831169\n",
      "Naive Bayes trained with 1255 features\n",
      "Logistic Regression trained with lambda: [10.]\n",
      "Decision Tree trained with aplha: 0.017254483115367286\n",
      "Random Forest trained with hyper-parameters: 130, auto\n",
      "bigram | tfidf:\n",
      "           Naive Bayes  Logistic Regression  Decision Tree  Random Forest\n",
      "recall        0.900000             0.937500       0.662500       0.812500\n",
      "precision     0.847059             0.797872       0.623529       0.773810\n",
      "accuracy      0.868750             0.850000       0.631250       0.787500\n",
      "f1            0.872727             0.862069       0.642424       0.792683\n",
      "Naive Bayes trained with 150 features\n",
      "Logistic Regression trained with lambda: [0.1]\n",
      "Decision Tree trained with aplha: 0.01339394291468185\n",
      "Random Forest trained with hyper-parameters: 140, sqrt\n",
      "unigram | countvec:\n",
      "           Naive Bayes  Logistic Regression  Decision Tree  Random Forest\n",
      "recall        0.725000             0.850000       0.650000       0.812500\n",
      "precision     0.716049             0.781609       0.641975       0.833333\n",
      "accuracy      0.718750             0.806250       0.643750       0.825000\n",
      "f1            0.720497             0.814371       0.645963       0.822785\n",
      "Naive Bayes trained with 1000 features\n",
      "Logistic Regression trained with lambda: [0.1]\n",
      "Decision Tree trained with aplha: 0.010713206998389069\n",
      "Random Forest trained with hyper-parameters: 130, auto\n",
      "bigram | countvec:\n",
      "           Naive Bayes  Logistic Regression  Decision Tree  Random Forest\n",
      "recall        0.912500             0.900000       0.725000       0.837500\n",
      "precision     0.811111             0.757895       0.637363       0.788235\n",
      "accuracy      0.850000             0.806250       0.656250       0.806250\n",
      "f1            0.858824             0.822857       0.678363       0.812121\n",
      "Naive Bayes trained with 1255 features\n",
      "Logistic Regression trained with lambda: [0.01]\n",
      "Decision Tree trained with aplha: 0.01339394291468185\n",
      "Random Forest trained with hyper-parameters: 140, sqrt\n",
      "unigram | binary:\n",
      "           Naive Bayes  Logistic Regression  Decision Tree  Random Forest\n",
      "recall            0.85             0.887500       0.750000       0.837500\n",
      "precision         0.85             0.755319       0.625000       0.817073\n",
      "accuracy          0.85             0.800000       0.650000       0.825000\n",
      "f1                0.85             0.816092       0.681818       0.827160\n",
      "Naive Bayes trained with 1255 features\n",
      "Logistic Regression trained with lambda: [0.1]\n",
      "Decision Tree trained with aplha: 0.013393942914681906\n",
      "Random Forest trained with hyper-parameters: 130, sqrt\n",
      "bigram | binary:\n",
      "           Naive Bayes  Logistic Regression  Decision Tree  Random Forest\n",
      "recall        0.850000             0.875000       0.650000       0.837500\n",
      "precision     0.790698             0.744681       0.641975       0.761364\n",
      "accuracy      0.812500             0.787500       0.643750       0.787500\n",
      "f1            0.819277             0.804598       0.645963       0.797619\n"
     ]
    }
   ],
   "source": [
    "def run_models(bigram = False, vec_type = \"tfidf\", min_df = False, compare_bigrams = False):\n",
    "    train = pd.read_csv(\"./train.csv\")\n",
    "    test = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "\n",
    "    if vec_type == \"tfidf\":\n",
    "        train_x, train_y, test_x, test_y = make_xy_train_test(train, test, bigram, min_df=min_df)\n",
    "    elif vec_type == \"countvec\":\n",
    "        train_x, train_y, test_x, test_y = make_countvec_xy_train_test(train, test, bigram, min_df=min_df)\n",
    "    elif vec_type == \"binary\":\n",
    "        train_x, train_y, test_x, test_y = make_countvec_xy_train_test(train, test, bigram, binary=True, min_df=min_df)\n",
    "    \n",
    "    data = {}\n",
    "    results = {}\n",
    "    results[\"test_y\"] = test_y\n",
    "\n",
    "    classifiers = [NaiveBayes(), LogRegClassifier(), TreeClassifier(), RandForestClassifier()]\n",
    "    for clf in classifiers:\n",
    "        print(f\"training {clf.name}\", end='\\r')\n",
    "        clf.train(train_x, train_y)\n",
    "        results[clf.name], data[clf.name] = clf.evaluate(test_x, test_y)\n",
    "\n",
    "    df = pd.DataFrame(data, \\\n",
    "        columns=[clf.name for clf in classifiers], \\\n",
    "        index=[\"recall\", \"precision\", \"accuracy\", \"f1\"])\n",
    "    print(f'{\"bigram\" if bigram else \"unigram\"} | {vec_type}:')\n",
    "    print(df)\n",
    "    return pd.DataFrame.from_dict(results)\n",
    "\n",
    "unitfidf = run_models(bigram=False, min_df=0.01)\n",
    "bitfidf = run_models(bigram=True, min_df=0.01)\n",
    "\n",
    "unicv = run_models(vec_type=\"countvec\", bigram=False, min_df=0.01)\n",
    "bicv = run_models(vec_type=\"countvec\", bigram=True, min_df=0.01)\n",
    "\n",
    "unibin = run_models(vec_type=\"binary\", bigram=False, min_df=0.01)\n",
    "bibin = run_models(vec_type=\"binary\", bigram=True, min_df=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def contingency(y_true, pred1, pred2):\n",
    "    cM = np.zeros((2,2))\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == pred1[i] and y_true[i] == pred2[i]:\n",
    "            cM[1,1] += 1\n",
    "        if y_true[i] != pred1[i] and y_true[i] == pred2[i]:\n",
    "            cM[0,1] += 1\n",
    "        if y_true[i] != pred1[i] and y_true[i] != pred2[i]:\n",
    "            cM[0,0] += 1\n",
    "        if y_true[i] == pred1[i] and y_true[i] != pred2[i]:\n",
    "            cM[1,0] += 1\n",
    "    return cM\n",
    "\n",
    "\n",
    "def calculateMcNemar(data = None, results = None, test_y = None):\n",
    "    if results.empty:\n",
    "        results = data.loc[:, data.columns != \"test_y\"]\n",
    "    if test_y.empty:\n",
    "        test_y = data[\"test_y\"]\n",
    "\n",
    "    McNemarScores = {}\n",
    "    for i in range(0, len(results.columns)):\n",
    "        for j in range(i + 1, len(results.columns)):\n",
    "            con = contingency(test_y, results.iloc[:,i], results.iloc[:,j])\n",
    "            mscore = mcnemar(con, exact = False)\n",
    "            McNemarScores[f\"{results.columns[i]} - {results.columns[j]}\"] = mscore\n",
    "            print(f\"{results.columns[i]} - {results.columns[j]} \\n {con} \\n statistic={mscore.statistic}, p-value={mscore.pvalue}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " uni tfidf\n",
      "Naive Bayes - Logistic Regression \n",
      " [[ 13.  13.]\n",
      " [  8. 126.]] \n",
      " statistic=0.7619047619047619, p-value=0.38273308888522595\n",
      "Naive Bayes - Decision Tree \n",
      " [[11. 15.]\n",
      " [46. 88.]] \n",
      " statistic=14.754098360655737, p-value=0.00012248100770987952\n",
      "Naive Bayes - Random Forest \n",
      " [[ 15.  11.]\n",
      " [ 15. 119.]] \n",
      " statistic=0.34615384615384615, p-value=0.5562984612747348\n",
      "Logistic Regression - Decision Tree \n",
      " [[10. 11.]\n",
      " [47. 92.]] \n",
      " statistic=21.120689655172413, p-value=4.312468453366182e-06\n",
      "Logistic Regression - Random Forest \n",
      " [[ 16.   5.]\n",
      " [ 14. 125.]] \n",
      " statistic=3.3684210526315788, p-value=0.0664574200169312\n",
      "Decision Tree - Random Forest \n",
      " [[18. 39.]\n",
      " [12. 91.]] \n",
      " statistic=13.254901960784315, p-value=0.0002718680028822981\n",
      "\n",
      " bi tfidf\n",
      "Naive Bayes - Logistic Regression \n",
      " [[ 12.  10.]\n",
      " [ 10. 128.]] \n",
      " statistic=0.05, p-value=0.8230632737581214\n",
      "Naive Bayes - Decision Tree \n",
      " [[11. 11.]\n",
      " [48. 90.]] \n",
      " statistic=21.966101694915253, p-value=2.7750883948169247e-06\n",
      "Naive Bayes - Random Forest \n",
      " [[ 13.   9.]\n",
      " [ 18. 120.]] \n",
      " statistic=2.3703703703703702, p-value=0.12365771040283367\n",
      "Logistic Regression - Decision Tree \n",
      " [[10. 12.]\n",
      " [49. 89.]] \n",
      " statistic=21.24590163934426, p-value=4.039732062360006e-06\n",
      "Logistic Regression - Random Forest \n",
      " [[ 16.   6.]\n",
      " [ 15. 123.]] \n",
      " statistic=3.0476190476190474, p-value=0.08085559837005234\n",
      "Decision Tree - Random Forest \n",
      " [[19. 40.]\n",
      " [12. 89.]] \n",
      " statistic=14.01923076923077, p-value=0.00018095049043756332\n",
      "\n",
      " uni countvec\n",
      "Naive Bayes - Logistic Regression \n",
      " [[ 14.   8.]\n",
      " [ 15. 123.]] \n",
      " statistic=1.565217391304348, p-value=0.21090292605660677\n",
      "Naive Bayes - Decision Tree \n",
      " [[ 6. 16.]\n",
      " [51. 87.]] \n",
      " statistic=17.253731343283583, p-value=3.2705462235166104e-05\n",
      "Naive Bayes - Random Forest \n",
      " [[ 13.   9.]\n",
      " [ 17. 121.]] \n",
      " statistic=1.8846153846153846, p-value=0.1698105050855175\n",
      "Logistic Regression - Decision Tree \n",
      " [[12. 17.]\n",
      " [45. 86.]] \n",
      " statistic=11.758064516129032, p-value=0.0006058018737316812\n",
      "Logistic Regression - Random Forest \n",
      " [[ 18.  11.]\n",
      " [ 12. 119.]] \n",
      " statistic=0.0, p-value=1.0\n",
      "Decision Tree - Random Forest \n",
      " [[20. 37.]\n",
      " [10. 93.]] \n",
      " statistic=14.382978723404255, p-value=0.00014914439102564321\n",
      "\n",
      " bi countvec\n",
      "Naive Bayes - Logistic Regression \n",
      " [[ 13.  10.]\n",
      " [ 16. 121.]] \n",
      " statistic=0.9615384615384616, p-value=0.3267995676689632\n",
      "Naive Bayes - Decision Tree \n",
      " [[13. 10.]\n",
      " [42. 95.]] \n",
      " statistic=18.48076923076923, p-value=1.7162735635942745e-05\n",
      "Naive Bayes - Random Forest \n",
      " [[ 15.   8.]\n",
      " [ 15. 122.]] \n",
      " statistic=1.565217391304348, p-value=0.21090292605660677\n",
      "Logistic Regression - Decision Tree \n",
      " [[16. 13.]\n",
      " [39. 92.]] \n",
      " statistic=12.01923076923077, p-value=0.000526544289648366\n",
      "Logistic Regression - Random Forest \n",
      " [[ 19.  10.]\n",
      " [ 11. 120.]] \n",
      " statistic=0.0, p-value=1.0\n",
      "Decision Tree - Random Forest \n",
      " [[21. 34.]\n",
      " [ 9. 96.]] \n",
      " statistic=13.395348837209303, p-value=0.000252249023327326\n",
      "\n",
      " uni binary\n",
      "Naive Bayes - Logistic Regression \n",
      " [[ 16.   8.]\n",
      " [ 18. 118.]] \n",
      " statistic=3.1153846153846154, p-value=0.07755616674366539\n",
      "Naive Bayes - Decision Tree \n",
      " [[ 7. 17.]\n",
      " [50. 86.]] \n",
      " statistic=15.283582089552239, p-value=9.251713772155624e-05\n",
      "Naive Bayes - Random Forest \n",
      " [[ 14.  10.]\n",
      " [ 22. 114.]] \n",
      " statistic=3.78125, p-value=0.05182992721790985\n",
      "Logistic Regression - Decision Tree \n",
      " [[20. 14.]\n",
      " [37. 89.]] \n",
      " statistic=9.490196078431373, p-value=0.0020657274310062934\n",
      "Logistic Regression - Random Forest \n",
      " [[ 21.  13.]\n",
      " [ 15. 111.]] \n",
      " statistic=0.03571428571428571, p-value=0.8501067391385259\n",
      "Decision Tree - Random Forest \n",
      " [[25. 32.]\n",
      " [11. 92.]] \n",
      " statistic=9.30232558139535, p-value=0.002288631539251969\n",
      "\n",
      " bi binary\n",
      "Naive Bayes - Logistic Regression \n",
      " [[ 16.   7.]\n",
      " [ 18. 119.]] \n",
      " statistic=4.0, p-value=0.04550026389635857\n",
      "Naive Bayes - Decision Tree \n",
      " [[10. 13.]\n",
      " [47. 90.]] \n",
      " statistic=18.15, p-value=2.04169428403451e-05\n",
      "Naive Bayes - Random Forest \n",
      " [[ 13.  10.]\n",
      " [ 11. 126.]] \n",
      " statistic=0.0, p-value=1.0\n",
      "Logistic Regression - Decision Tree \n",
      " [[21. 13.]\n",
      " [36. 90.]] \n",
      " statistic=9.877551020408163, p-value=0.0016730747221523179\n",
      "Logistic Regression - Random Forest \n",
      " [[ 19.  15.]\n",
      " [  5. 121.]] \n",
      " statistic=4.05, p-value=0.04417134490844271\n",
      "Decision Tree - Random Forest \n",
      " [[18. 39.]\n",
      " [ 6. 97.]] \n",
      " statistic=22.755555555555556, p-value=1.839715194954409e-06\n"
     ]
    }
   ],
   "source": [
    "#McNemar scores of each classification algorith compared with each other\n",
    "\n",
    "print(\"\\n uni tfidf\")\n",
    "calculateMcNemar(unitfidf)\n",
    "print(\"\\n bi tfidf\")\n",
    "calculateMcNemar(bitfidf)\n",
    "print(\"\\n uni countvec\")\n",
    "calculateMcNemar(unicv)\n",
    "\n",
    "#bigram features\n",
    "print(\"\\n bi countvec\")\n",
    "calculateMcNemar(bicv)\n",
    "print(\"\\n uni binary\")\n",
    "calculateMcNemar(unibin)\n",
    "print(\"\\n bi binary\")\n",
    "calculateMcNemar(bibin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TFIDF Unigram vs Bigram\nNaive Bayes unigram vs bigram\n   unigram  bigram\n0        1       1\n1        0       0\n2        0       0\n3        0       0\n4        0       0\nunigram - bigram \n [[ 13.   8.]\n [  8. 131.]] \n statistic=0.0625, p-value=0.8025873486341526\nLogistic Regression unigram vs bigram\n   unigram  bigram\n0        1       1\n1        0       0\n2        0       0\n3        0       0\n4        0       0\nunigram - bigram \n [[ 19.   6.]\n [  5. 130.]] \n statistic=0.0, p-value=1.0\nDecision Tree unigram vs bigram\n   unigram  bigram\n0        0       0\n1        0       0\n2        0       1\n3        0       0\n4        0       0\nunigram - bigram \n [[50.  6.]\n [ 9. 95.]] \n statistic=0.26666666666666666, p-value=0.6055766163353462\nRandom Forest unigram vs bigram\n   unigram  bigram\n0        0       0\n1        0       0\n2        0       0\n3        0       0\n4        0       0\nunigram - bigram \n [[ 15.  11.]\n [ 19. 115.]] \n statistic=1.6333333333333333, p-value=0.20124262095772028\n--------------------------  \n\n CountVector Unigram vs Bigram\nNaive Bayes unigram vs bigram\n   unigram  bigram\n0        1       1\n1        1       0\n2        1       0\n3        1       0\n4        0       0\nunigram - bigram \n [[ 13.  32.]\n [ 11. 104.]] \n statistic=9.30232558139535, p-value=0.002288631539251969\nLogistic Regression unigram vs bigram\n   unigram  bigram\n0        1       1\n1        0       0\n2        0       0\n3        0       1\n4        0       0\nunigram - bigram \n [[ 27.   4.]\n [  4. 125.]] \n statistic=0.125, p-value=0.7236736098317629\nDecision Tree unigram vs bigram\n   unigram  bigram\n0        0       0\n1        0       0\n2        0       0\n3        0       0\n4        0       0\nunigram - bigram \n [[51.  6.]\n [ 4. 99.]] \n statistic=0.1, p-value=0.7518296340458492\nRandom Forest unigram vs bigram\n   unigram  bigram\n0        0       0\n1        0       0\n2        0       0\n3        0       0\n4        0       1\nunigram - bigram \n [[ 19.   9.]\n [ 12. 120.]] \n statistic=0.19047619047619047, p-value=0.6625205835400574\n--------------------------  \n\n Binary Unigram vs Bigram\nNaive Bayes unigram vs bigram\n   unigram  bigram\n0        1       1\n1        0       0\n2        0       0\n3        0       0\n4        0       0\nunigram - bigram \n [[ 20.   4.]\n [ 10. 126.]] \n statistic=1.7857142857142858, p-value=0.18144920772141646\nLogistic Regression unigram vs bigram\n   unigram  bigram\n0        0       0\n1        0       0\n2        0       0\n3        0       0\n4        0       0\nunigram - bigram \n [[ 30.   2.]\n [  4. 124.]] \n statistic=0.16666666666666666, p-value=0.6830913983096086\nDecision Tree unigram vs bigram\n   unigram  bigram\n0        0       0\n1        0       0\n2        0       0\n3        0       0\n4        0       0\nunigram - bigram \n [[49.  7.]\n [ 8. 96.]] \n statistic=0.0, p-value=1.0\nRandom Forest unigram vs bigram\n   unigram  bigram\n0        0       1\n1        0       0\n2        0       0\n3        0       0\n4        0       1\nunigram - bigram \n [[ 19.   9.]\n [ 15. 117.]] \n statistic=1.0416666666666667, p-value=0.30743416592739237\n"
     ]
    }
   ],
   "source": [
    "#comparing unigram vs bigram results of same models\n",
    "\n",
    "def compareBigramScore(test_y, model, unigram, bigram):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"unigram\"] = unigram\n",
    "    df[\"bigram\"] = bigram\n",
    "    print(f\"{model} unigram vs bigram\")\n",
    "    print(df.head())\n",
    "    calculateMcNemar(results = df, test_y = test_y)\n",
    "\n",
    "\n",
    "print(\"TFIDF Unigram vs Bigram\")\n",
    "testmodel = \"Naive Bayes\"\n",
    "compareBigramScore(unitfidf[\"test_y\"], testmodel, unitfidf[testmodel], bitfidf[testmodel])\n",
    "testmodel = \"Logistic Regression\"\n",
    "compareBigramScore(unitfidf[\"test_y\"], testmodel, unitfidf[testmodel], bitfidf[testmodel])\n",
    "testmodel = \"Decision Tree\"\n",
    "compareBigramScore(unitfidf[\"test_y\"], testmodel, unitfidf[testmodel], bitfidf[testmodel])\n",
    "testmodel = \"Random Forest\"\n",
    "compareBigramScore(unitfidf[\"test_y\"], testmodel, unitfidf[testmodel], bitfidf[testmodel])\n",
    "\n",
    "print(\"--------------------------  \\n\\n CountVector Unigram vs Bigram\")\n",
    "testmodel = \"Naive Bayes\"\n",
    "compareBigramScore(unicv[\"test_y\"], testmodel, unicv[testmodel], bicv[testmodel])\n",
    "testmodel = \"Logistic Regression\"\n",
    "compareBigramScore(unicv[\"test_y\"], testmodel, unicv[testmodel], bicv[testmodel])\n",
    "testmodel = \"Decision Tree\"\n",
    "compareBigramScore(unicv[\"test_y\"], testmodel, unicv[testmodel], bicv[testmodel])\n",
    "testmodel = \"Random Forest\"\n",
    "compareBigramScore(unicv[\"test_y\"], testmodel, unicv[testmodel], bicv[testmodel])\n",
    "\n",
    "print(\"--------------------------  \\n\\n Binary Unigram vs Bigram\")\n",
    "testmodel = \"Naive Bayes\"\n",
    "compareBigramScore(unibin[\"test_y\"], testmodel, unibin[testmodel], bibin[testmodel])\n",
    "testmodel = \"Logistic Regression\"\n",
    "compareBigramScore(unibin[\"test_y\"], testmodel, unibin[testmodel], bibin[testmodel])\n",
    "testmodel = \"Decision Tree\"\n",
    "compareBigramScore(unibin[\"test_y\"], testmodel, unibin[testmodel], bibin[testmodel])\n",
    "testmodel = \"Random Forest\"\n",
    "compareBigramScore(unibin[\"test_y\"], testmodel, unibin[testmodel], bibin[testmodel])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}